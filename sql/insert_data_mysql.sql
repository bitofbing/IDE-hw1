-- 插入PPT文件记录（假设文件已存在）
INSERT INTO ppt_files VALUES (
    'f001',
    '第1章_关系数据库查询优化.pptx',
    25,
    '2025-01-15 10:00:00',
    '5f8d8a7d6b8f4e3d2c1b0a9f'
);

-- 插入PPT页面记录
INSERT INTO ppt_pages VALUES
('p001', 'f001', 1, '基数估计概述', '基数估计概述 (1)', '["基数估计","查询优化"]'),
('p002', 'f001', 2, '基数估计概述', '基数估计概述 (2)', '["规模分布","估计器"]'),
('p003', 'f001', 3, '传统基数估计方法', '传统基数估计方法 (1)', '["采样","缩放"]'),
('p004', 'f001', 4, '传统基数估计方法', '传统基数估计方法 (2)', '["统计分析","直方图"]'),
('p008', 'f001', 8, '传统基数估计方法', '传统基数估计方法 (8)', '["多表查询","连接"]'),
('p007', 'f001', 7, '基于机器学习的基数估计', '基于机器学习的基数估计 (7)', '["神经网络","乘积项"]'),
('p999', 'f001', 99, '总结', '总结', '["查询优化器","决策"]');

-- 插入实体数据
INSERT INTO entities VALUES
('ent1', '查询优化器', '概念', '负责选择最优查询执行计划的组件', '基数估计概述 (1)', 'p001'),
('ent2', '基数估计', '方法', '估计查询结果集大小的技术', '基数估计概述 (1)', 'p001'),
('ent3', '规模分布估计器', '技术', '预测数据规模分布的工具', '基数估计概述 (2)', 'p002'),
('ent4', '采样结果', '数据', '从数据集中抽取的样本结果', '传统基数估计方法 (1)', 'p003'),
('ent5', '目标列', '属性', '需要进行统计分析的数据列', '传统基数估计方法 (2)', 'p004'),
('ent6', '直方图类型', '方法', '表示数据分布的直方图分类', '传统基数估计方法 (2)', 'p004'),
('ent7', '采样方法', '方法', '从大数据集中抽取样本的技术', '传统基数估计方法 (8)', 'p008'),
('ent8', '摘要信息', '数据', '经过汇总的简化数据表示', '传统基数估计方法 (8)', 'p008'),
('ent9', '多表查询', '操作', '涉及多个表的查询操作', '传统基数估计方法 (8)', 'p008'),
('ent10', '第一个乘积项', '属性', '神经网络模型中的首个计算项', '基于机器学习的基数估计 (7)', 'p007');

-- 插入关系数据
INSERT INTO relations VALUES
('rel1', 'ent1', 'ent2', '需要估计', '查询优化器需要基数估计来预测数据分布'),
('rel2', 'ent2', 'ent3', '等价于', '基数估计与规模分布估计器是同一概念'),
('rel3', 'ent4', 'ent2', '通过缩放得到', '采样结果通过缩放可以得到基数估计值'),
('rel4', 'ent5', 'ent2', '使用部分记录进行', '目标列使用部分记录进行统计分析'),
('rel5', 'ent6', 'ent2', '匹配数据分布特征', '直方图类型需要匹配数据分布特征'),
('rel6', 'ent7', 'ent2', '用于缩减数据规模', '采样方法用于缩减查询数据规模'),
('rel7', 'ent8', 'ent2', '通过连接筛选生成', '摘要信息通过连接筛选生成基数估计'),
('rel8', 'ent9', 'ent2', '需要单独采样各表', '多表查询需要单独采样各表'),
('rel9', 'ent10', 'ent2', '对应神经网络输入', '第一个乘积项对应神经网络输入特征'),
('rel10', 'ent2', 'ent1', '支撑决策', '基数估计支撑查询优化器决策');

-- 插入引用数据
INSERT INTO citations VALUES
('cit1', 'ent1', 'rel1', '估计查询涉及数据对象的大小分布情况（查询结果大小、可能取值频率分布）', '基数估计概述 (1)', 'p001', 'BODY'),
('cit2', 'ent2', 'rel2', '基数估计和规模分布估计器有什么关系？等价', '基数估计概述 (2)', 'p002', 'BODY'),
('cit3', 'ent4', 'rel3', '根据在采样集上执行查询得到的结果大小除以相应缩放比例得到基数估计结果', '传统基数估计方法 (1)', 'p003', 'BODY'),
('cit4', 'ent5', 'rel4', '目标列中用于统计分析的记录占总记录数的百分比', '传统基数估计方法 (2)', 'p004', 'BODY'),
('cit5', 'ent6', 'rel5', '不同类型的直方图对应不同的基数估计方法，根据数据列的不同分布情况选择适合的直方图', '传统基数估计方法 (2)', 'p004', 'BODY'),
('cit6', 'ent7', 'rel6', '使用采样的方法对查询数据进行缩放', '传统基数估计方法 (8)', 'p008', 'BODY'),
('cit7', 'ent8', 'rel7', '通过对摘要信息进行连接和筛选得到采样基数值', '传统基数估计方法 (8)', 'p008', 'BODY'),
('cit8', 'ent9', 'rel8', '单独对每个表进行采样，再将采样结果连接并进行查询并缩放', '传统基数估计方法 (8)', 'p008', 'BODY'),
('cit9', 'ent10', 'rel9', '第一个乘积项对应的神经网络输入是什么？', '基于机器学习的基数估计 (7)', 'p007', 'BODY'),
('cit10', 'ent2', 'rel10', '基数估计用于查询优化器的规模分布估计器', '总结', 'p999', 'BODY');

-- 插入页面定位数据
INSERT INTO page_locations VALUES
('loc1', 'p001', 'ent1', 'rel1', 100, 200, 300, 400, 'TEXT'),
('loc2', 'p002', 'ent2', 'rel2', 150, 250, 350, 450, 'TEXT'),
('loc3', 'p003', 'ent4', 'rel3', 200, 300, 400, 500, 'TEXT'),
('loc4', 'p004', 'ent5', 'rel4', 250, 350, 450, 550, 'TEXT'),
('loc5', 'p004', 'ent6', 'rel5', 300, 400, 500, 600, 'TEXT'),
('loc6', 'p008', 'ent7', 'rel6', 350, 450, 550, 650, 'TEXT'),
('loc7', 'p008', 'ent8', 'rel7', 400, 500, 600, 700, 'TEXT'),
('loc8', 'p008', 'ent9', 'rel8', 450, 550, 650, 750, 'TEXT'),
('loc9', 'p007', 'ent10', 'rel9', 500, 600, 700, 800, 'TEXT'),
('loc10', 'p999', 'ent2', 'rel10', 550, 650, 750, 850, 'TEXT');

-- 插入PPT文件记录（第2章）
INSERT INTO ppt_files VALUES (
    'f002',
    '第2章_信息检索.pptx',
    30,
    NOW(),
    '5f8d8a7d6b8f4e3d2c1b0a9e'
);

-- 插入PPT页面记录
INSERT INTO ppt_pages VALUES
('p201', 'f002', 1, '信息检索模型', '向量空间模型', '["VSM","词频","权重"]'),
('p202', 'f002', 2, '信息检索模型', 'TF-IDF计算', '["局部权值","全局权值"]'),
('p203', 'f002', 3, '文本信息检索', '文本预处理', '["分词","词干提取"]'),
('p204', 'f002', 4, 'Web信息检索', 'PageRank算法', '["链接分析","排序"]'),
('p207', 'f002', 7, 'Web信息检索', 'HITS算法', '["权威网页","Hub页面"]');

-- 插入实体数据
INSERT INTO entities VALUES
('e201', '文档向量', '模型组件', '向量空间模型中的文档表示形式', '信息检索模型 (1)', 'p201'),
('e202', '零值', '属性', '向量中表示词汇不存在的标记', '信息检索模型 (1)', 'p201'),
('e203', '词kᵢ', '元素', '文档中的索引项/词汇', '信息检索模型 (2)', 'p202'),
('e204', '最大词频', '统计量', '文档中所有词出现次数的最大值', '信息检索模型 (3)', 'p202'),
('e205', 'agent', '实例词汇', '示例索引词k₁', '信息检索模型 (4)', 'p202'),
('e206', '文本"人工智能正"', '文本实例', '中文分词示例文本', '文本信息检索 (1)', 'p203'),
('e207', '文本信息检索', '技术领域', '主要处理文本数据的检索技术', '文本信息检索 (1)', 'p203'),
('e208', '齐普夫定律', '统计规律', '描述词频与排名关系的法则', '文本信息检索 (1)', 'p203'),
('e209', '查询词', '查询元素', '用户提问式中的词汇', '文本信息检索 (2)', 'p203'),
('e210', '倒排索引', '数据结构', '记录词项到文档的映射', '文本信息检索 (3)', 'p203'),
('e211', '政府计划', '文本实例', '网页去重特征提取示例', 'Web信息检索 (2)', 'p204'),
('e212', '高链接数', '网页属性', '网页被其他网页引用的次数', 'Web信息检索 (4)', 'p204'),
('e213', '游走概率', '算法参数', '随机游走中的转移概率', 'Web信息检索 (6)', 'p204'),
('e214', '权威网页', '网页类型', '提供高质量内容的网页', 'Web信息检索 (7)', 'p207');

-- 插入关系数据
INSERT INTO relations VALUES
('r201', 'e201', 'e202', '包含', '文档向量包含表示词不存在的位置值'),
('r202', 'e203', 'e201', '具有', '词kᵢ在文档向量中的局部权值'),
('r203', 'e203', 'e201', '具有', '词kᵢ在整个文档集中的全局权值'),
('r204', 'e203', 'e201', '出现于', '词kᵢ在文档dⱼ中的出现频率'),
('r205', 'e204', 'e202', '用于', '最大词频用于消除文档长度偏差'),
('r206', 'e205', 'e201', '出现于', '示例词agent在文档d₁中的出现次数'),
('r207', 'e206', 'e203', '分词为', '中文文本的分词处理示例'),
('r208', 'e207', 'e201', '主要处理', '文本信息检索的核心数据类型'),
('r209', 'e208', 'e203', '描述', '齐普夫定律描述词频分布规律'),
('r210', 'e209', 'e210', '映射到', '查询词映射到倒排索引表'),
('r211', 'e210', 'e203', '记录', '倒排索引记录词项位置信息'),
('r212', 'e211', 'e203', '包含动作', '政府计划文本中的动作特征'),
('r213', 'e212', 'e214', '导致', '高链接数使网页更受关注'),
('r214', 'e213', 'e212', '决定', '游走概率决定节点排序结果'),
('r215', 'e214', 'e207', '提供', '权威网页提供高质量内容');

-- 插入引用数据
INSERT INTO citations VALUES
('c201', 'e201', 'r201', '文档dᵢ的向量在位置j上的值为x', '信息检索模型 (1)', 'p201', 'BODY'),
('c202', 'e202', 'r201', '值为0表示该词没有在该文档中出现', '信息检索模型 (1)', 'p201', 'BODY'),
('c203', 'e203', 'r202', 'fᵢⱼ=freqᵢⱼ/max tfⱼ — 第i个词在第j个文档中的权值', '信息检索模型 (2)', 'p202', 'BODY'),
('c204', 'e203', 'r203', 'idfᵢ=log(n/nᵢ) — 第i个词在整个文档集中的权值', '信息检索模型 (2)', 'p202', 'BODY'),
('c205', 'e203', 'r204', 'freqᵢⱼ — kᵢ在dⱼ中出现的次数', '信息检索模型 (3)', 'p202', 'BODY'),
('c206', 'e204', 'r205', 'max tfⱼ — 消除文档长度对词权的影响', '信息检索模型 (3)', 'p202', 'BODY'),
('c207', 'e205', 'r206', '索引词k₁(agent)在文档d₁中出现的次数freq₁₁=2', '信息检索模型 (4)', 'p202', 'EXAMPLE'),
('c208', 'e206', 'r207', '人工智能正在改变世界 → 人工智能，改变，世界', '文本信息检索 (1)', 'p203', 'EXAMPLE'),
('c209', 'e207', 'r208', '文本信息检索主要对象是文本数据', '文本信息检索 (1)', 'p203', 'BODY'),
('c210', 'e208', 'r209', '词频f=C/rᵝ，揭示词频和词排名之间的关系', '文本信息检索 (1)', 'p203', 'BODY'),
('c211', 'e209', 'r210', '提问式q中所有词对应的倒排表', '文本信息检索 (2)', 'p203', 'BODY'),
('c212', 'e210', 'r211', '获得词的文档号及在文档中出现的位置', '文本信息检索 (3)', 'p203', 'BODY'),
('c213', 'e211', 'r212', '政府计划增加教育预算 → 政府、计划、增加、教育、预算', 'Web信息检索 (2)', 'p204', 'EXAMPLE'),
('c214', 'e212', 'r213', '若一个网页被较多的其他网页链接，则它相对较被人关注', 'Web信息检索 (4)', 'p204', 'BODY'),
('c215', 'e213', 'r214', '多轮游走后，依据概率对剩余节点进行排序', 'Web信息检索 (6)', 'p204', 'BODY'),
('c216', 'e214', 'r215', '权威性网页对于检索而言是高质量的内容网页', 'Web信息检索 (7)', 'p207', 'BODY');

-- 插入页面定位数据
INSERT INTO page_locations VALUES
('loc201', 'p201', 'e201', 'r201', 100, 150, 400, 200, 'TEXT'),
('loc202', 'p201', 'e202', NULL, 120, 180, 420, 220, 'TEXT'),
('loc203', 'p202', 'e203', 'r202', 80, 130, 380, 180, 'FORMULA'),
('loc204', 'p202', 'e203', 'r203', 90, 140, 390, 190, 'FORMULA'),
('loc205', 'p202', 'e204', 'r205', 100, 150, 400, 200, 'TEXT'),
('loc206', 'p202', 'e205', 'r206', 110, 160, 410, 210, 'EXAMPLE'),
('loc207', 'p203', 'e206', 'r207', 70, 120, 370, 170, 'EXAMPLE'),
('loc208', 'p203', 'e207', 'r208', 80, 130, 380, 180, 'TEXT'),
('loc209', 'p203', 'e208', 'r209', 90, 140, 390, 190, 'FORMULA'),
('loc210', 'p203', 'e209', 'r210', 100, 150, 400, 200, 'TEXT'),
('loc211', 'p203', 'e210', 'r211', 110, 160, 410, 210, 'TEXT'),
('loc212', 'p204', 'e211', 'r212', 120, 170, 420, 220, 'EXAMPLE'),
('loc213', 'p204', 'e212', 'r213', 130, 180, 430, 230, 'TEXT'),
('loc214', 'p204', 'e213', 'r214', 140, 190, 440, 240, 'TEXT'),
('loc215', 'p207', 'e214', 'r215', 150, 200, 450, 250, 'TEXT');

-- =============================================
-- 第3章 数据组织 知识图谱数据
-- =============================================

-- 1. 插入PPT文件记录
INSERT INTO ppt_files VALUES (
    'f003',
    '第3章_数据组织.pptx',
    35,
    NOW(),
    '6g9e9b8c7f6e5d4c3b2a1f'
);

-- 2. 插入PPT页面记录
INSERT INTO ppt_pages VALUES
('p301', 'f003', 1, '数据组织概述', '数据内涵与发展', '["定义","发展脉络"]'),
('p302', 'f003', 2, '数据仓库', '基本特征', '["面向主题","集成","时变"]'),
('p303', 'f003', 3, '数据仓库', '体系结构', '["ETL","数据集市"]'),
('p304', 'f003', 4, '数据湖', '核心概念', '["原始格式","按需处理"]'),
('p305', 'f003', 5, '数据湖', '数据池体系', '["初始池","模拟池","应用池"]'),
('p306', 'f003', 6, '数据湖', 'Hudi框架', '["时间轴","快照查询"]'),
('p307', 'f003', 7, '向量数据库', '索引技术', '["KD树","LSH","HNSW"]'),
('p308', 'f003', 8, '向量数据库', '搜索技术', '["欧氏距离","余弦相似度"]'),
('p309', 'f003', 9, '向量数据库', '产品介绍', '["Milvus","Pinecone"]'),
('p310', 'f003', 10, '总结', '关键技术对比', '["仓库vs数据湖","索引对比"]');

-- 3. 插入实体数据
INSERT INTO entities VALUES
-- 数据组织核心概念
('e301', '数据组织', '方法论', '数据的归并、存储、处理过程', '数据组织概述 (1)', 'p301'),
('e302', '传统数据库', '系统', '20世纪70年代的数据管理系统', '数据组织概述 (2)', 'p301'),
('e303', '数据中台', '架构', '企业级数据服务设施', '数据组织概述 (2)', 'p301'),

-- 数据仓库相关
('e304', '数据仓库', '系统', '面向主题的集成数据存储', '数据仓库 (1)', 'p302'),
('e305', 'ETL工具', '组件', '数据抽取-转换-加载工具集', '数据仓库 (4)', 'p303'),
('e306', '数据集市', '子系统', '部门级数据仓库子集', '数据仓库 (5)', 'p303'),
('e307', '操作型数据存储', '组件', '实时数据集成层', '数据仓库 (6)', 'p303'),

-- 数据湖相关
('e308', '数据湖', '系统', '原始数据存储管理系统', '数据湖 (1)', 'p304'),
('e309', '初始数据池', '存储层', '原始数据存储区域', '数据湖 (5)', 'p305'),
('e310', '模拟数据池', '处理层', '半结构化数据处理区', '数据湖 (5)', 'p305'),
('e311', 'Hudi', '框架', 'Hadoop增删改查框架', '数据湖 (8)', 'p306'),

-- 向量数据库相关
('e312', '向量数据库', '系统', '高维向量数据管理系统', '向量数据库 (1)', 'p307'),
('e313', 'KD树', '索引', '多维空间划分树结构', '向量数据库 (2)', 'p307'),
('e314', 'LSH', '算法', '局部敏感哈希算法', '向量数据库 (4)', 'p307'),
('e315', 'HNSW', '索引', '分层导航小世界图', '向量数据库 (5)', 'p307'),
('e316', 'Milvus', '产品', '开源向量数据库', '向量数据库 (7)', 'p309'),
('e317', 'Pinecone', '产品', '云原生向量数据库', '向量数据库 (8)', 'p309'),
('e318', 'Faiss', '库', 'Facebook相似性搜索库', '向量数据库 (12)', 'p309');

-- 4. 插入关系数据
INSERT INTO relations VALUES
-- 数据组织发展脉络
('r301', 'e302', 'e301', '属于', '传统数据库是早期数据组织形式', '历史演进'),
('r302', 'e304', 'e301', '属于', '数据仓库是中期数据组织形式', '历史演进'),
('r303', 'e308', 'e301', '属于', '数据湖是现代数据组织形式', '历史演进'),

-- 数据仓库体系
('r304', 'e304', 'e305', '包含', '数据仓库包含ETL处理环节', '架构组成'),
('r305', 'e304', 'e306', '派生', '数据集市派生自数据仓库', '架构关系'),
('r306', 'e304', 'e307', '包含', '操作型数据存储是中间层', '架构组成'),

-- 数据湖体系
('r307', 'e308', 'e309', '包含', '数据湖包含初始数据池', '存储架构'),
('r308', 'e308', 'e310', '包含', '数据湖包含模拟数据池', '处理架构'),
('r309', 'e308', 'e311', '使用', '数据湖可使用Hudi框架', '技术实现'),

-- 向量数据库技术
('r310', 'e312', 'e313', '支持', '向量数据库支持KD树索引', '索引技术'),
('r311', 'e312', 'e314', '支持', '向量数据库支持LSH算法', '索引技术'),
('r312', 'e312', 'e315', '支持', '向量数据库支持HNSW索引', '索引技术'),

-- 产品能力
('r313', 'e316', 'e313', '实现', 'Milvus实现KD树索引', '产品特性'),
('r314', 'e317', 'e314', '优化', 'Pinecone优化LSH算法', '产品特性'),
('r315', 'e318', 'e315', '扩展', 'Faiss扩展HNSW应用', '产品特性');

-- 5. 插入引用数据
INSERT INTO citations VALUES
-- 核心概念引用
('c301', 'e301', NULL, '按照一定的方式和规则对数据进行归并、存储、处理的过程', '数据组织概述 (1)', 'p301', 'DEFINITION'),
('c302', 'e304', NULL, '面向主题的、集成的、时变的、不可更新的数据集合', '数据仓库 (1)', 'p302', 'DEFINITION'),
('c303', 'e308', NULL, '以原始数据格式接收和存储数据的灵活系统', '数据湖 (1)', 'p304', 'DEFINITION'),

-- 技术原理引用
('c304', 'e313', 'r310', '采用递归方式选择维度进行划分的树结构', '向量数据库 (3)', 'p307', 'ALGORITHM'),
('c305', 'e314', 'r311', '若两个数据点在原始空间中相近，则其哈希值也相近', '向量数据库 (4)', 'p307', 'PRINCIPLE'),
('c306', 'e311', NULL, '通过时间轴管理数据文件的变更历史', '数据湖 (8)', 'p306', 'MECHANISM'),

-- 产品特性引用
('c307', 'e316', 'r313', '兼容多种索引类型，具备高效的搜索功能', '向量数据库 (7)', 'p309', 'FEATURE'),
('c308', 'e317', NULL, '采用分布式架构，支持水平扩展', '向量数据库 (8)', 'p309', 'ARCHITECTURE'),
('c309', 'e318', 'r315', '通过优化算法和硬件加速实现高性能搜索', '向量数据库 (12)', 'p309', 'PERFORMANCE');

-- 6. 插入页面定位数据
INSERT INTO page_locations VALUES
-- 核心概念定位
('loc301', 'p301', 'e301', NULL, 100, 120, 400, 180, 'TITLE'),
('loc302', 'p302', 'e304', NULL, 80, 150, 420, 200, 'DIAGRAM'),
('loc303', 'p304', 'e308', NULL, 90, 160, 410, 210, 'DEFINITION'),

-- 技术原理定位
('loc304', 'p307', 'e313', 'r310', 150, 200, 450, 250, 'FORMULA'),
('loc305', 'p307', 'e314', 'r311', 160, 210, 460, 260, 'ALGORITHM'),
('loc306', 'p306', 'e311', NULL, 140, 190, 440, 240, 'FRAMEWORK'),

-- 产品介绍定位
('loc307', 'p309', 'e316', 'r313', 180, 230, 480, 280, 'PRODUCT'),
('loc308', 'p309', 'e317', NULL, 170, 220, 470, 270, 'PRODUCT'),
('loc309', 'p309', 'e318', 'r315', 190, 240, 490, 290, 'LIBRARY');

-- 7. 插入历史版本数据（示例）
INSERT INTO page_versions VALUES
('ver301', 'p307', '{"content":"原始向量索引技术描述"}', 'system', NOW()),
('ver302', 'p309', '{"products":["Milvus 1.0"]}', 'admin', NOW());

-- 8. 实体-页面关系历史（示例）
INSERT INTO entity_page_history VALUES
('hist301', 'e312', NULL, 'p307', '初始关联向量数据库章节', NOW()),
('hist302', 'e316', NULL, 'p309', '添加Milvus产品介绍', NOW());

-- =============================================
-- 第4章 高维数据挖掘 知识图谱数据
-- =============================================

-- 1. 插入PPT文件记录
INSERT INTO ppt_files VALUES (
    'f004',
    '第4章_高维数据挖掘.pptx',
    40,
    NOW(),
    '7h0f1a2b3c4d5e6f7g8h9i'
);

-- 2. 插入PPT页面记录
INSERT INTO ppt_pages VALUES
('p401', 'f004', 1, '引例', 'MNIST数据集案例', '["维度灾难","降维"]'),
('p402', 'f004', 2, '高维数据挖掘概述', '核心问题', '["降维","分类","聚类"]'),
('p403', 'f004', 3, '数据降维', '自编码器技术', '["编码器","解码器"]'),
('p404', 'f004', 4, '数据分类', '贝叶斯方法', '["朴素贝叶斯","概率计算"]'),
('p405', 'f004', 5, '数据聚类', 'k-means算法', '["簇中心","迭代优化"]'),
('p406', 'f004', 6, '总结', '算法对比', '["优点","缺点"]');

-- 3. 插入实体数据
INSERT INTO entities VALUES
-- 核心概念
('e401', '特征分析', '方法', '对数据特征的提取和处理技术', '引例 (4)', 'p401'),
('e402', '高维数据', '数据类型', '维度特征远高于样本数的数据', '高维数据挖掘概述 (1)', 'p402'),
('e403', '维度灾难', '问题', '高维空间中的数据稀疏性问题', '高维数据挖掘概述 (1)', 'p402'),
('e404', '降维技术', '技术', '降低数据维度的方法总称', '高维数据挖掘概述 (1)', 'p402'),
('e405', '非线性降维', '技术', '保持非线性特征的降维方法', '高维数据挖掘概述 (2)', 'p402'),
('e406', '线性降维', '技术', '基于线性变换的降维方法', '高维数据挖掘概述 (2)', 'p402'),
('e407', '聚类算法', '算法', '数据分组的技术集合', '高维数据挖掘概述 (3)', 'p402'),
('e408', '距离度量', '方法', '计算对象相似性的标准', '高维数据挖掘概述 (5)', 'p402'),

-- 降维技术
('e409', '自编码器', '模型', '通过编码-解码实现降维的神经网络', '数据降维 (2)', 'p403'),
('e410', '编码器', '组件', '实现数据降维的网络部分', '数据降维 (2)', 'p403'),
('e411', '解码器', '组件', '实现数据重构的网络部分', '数据降维 (3)', 'p403'),

-- 分类算法
('e412', '贝叶斯分类', '算法', '基于概率统计的分类方法', '数据分类 (1)', 'p404'),
('e413', 'SVM', '算法', '支持向量机分类器', '数据分类 (10)', 'p404'),
('e414', '超平面', '概念', '分类决策边界', '数据分类 (10)', 'p404'),
('e415', '核函数', '方法', '解决非线性问题的映射技术', '数据分类 (16)', 'p404'),

-- 聚类算法
('e416', '层次聚类', '算法', '基于层次结构的聚类方法', '数据聚类 (2)', 'p405'),
('e417', '网格聚类', '算法', '基于空间划分的聚类方法', '数据聚类 (3)', 'p405'),
('e418', 'MapReduce', '框架', '分布式计算框架', '数据聚类 (4)', 'p405'),
('e419', 'k-means', '算法', '基于中心点迭代的聚类算法', '数据聚类 (6)', 'p405'),
('e420', '目标函数', '标准', '聚类质量评估指标', '数据聚类 (5)', 'p405');

-- 4. 插入关系数据
INSERT INTO relations VALUES
-- 应用场景
('r401', 'e401', 'e401', '用于', '特征分析用于客户分类'),

-- 高维数据问题
('r402', 'e402', 'e403', '导致', '高维数据导致维度灾难'),
('r403', 'e404', 'e404', '发现', '降维技术发现低维特征'),

-- 技术关系
('r404', 'e405', 'e406', '基于', '非线性降维基于线性技术'),
('r405', 'e406', 'e406', '局限', '线性降维局限在保持非线性'),
('r406', 'e409', 'e410', '包含', '自编码器包含编码器组件'),
('r407', 'e409', 'e411', '包含', '自编码器包含解码器组件'),

-- 分类算法
('r408', 'e412', 'e412', '计算', '贝叶斯分类计算类别概率'),
('r409', 'e413', 'e414', '寻找', 'SVM寻找分类超平面'),
('r410', 'e415', 'e415', '解决', '核函数解决非线性问题'),

-- 聚类算法
('r411', 'e407', 'e407', '划分', '聚类算法划分互斥子集'),
('r412', 'e416', 'e416', '初始化', '层次聚类初始化单对象簇'),
('r413', 'e417', 'e417', '映射', '网格聚类映射单元对象'),
('r414', 'e418', 'e407', '扩展', 'MapReduce扩展聚类算法'),
('r415', 'e419', 'e419', '选择', 'k-means选择初始中心'),
('r416', 'e420', 'e420', '度量', '目标函数度量簇内紧密度'),

-- 算法特性
('r417', 'e412', 'e412', '存在', '朴素贝叶斯存在决策错误率'),
('r418', 'e409', 'e409', '依赖', '模型性能依赖参数调优');

-- 5. 插入引用数据
INSERT INTO citations VALUES
-- 核心概念
('c401', 'e401', 'r401', '如何对客户的某些特征进行分类', '引例 (4)', 'p401', 'APPLICATION'),
('c402', 'e402', 'r402', '高维数据存在维度灾难问题', '高维数据挖掘概述 (1)', 'p402', 'PROBLEM'),
('c403', 'e404', 'r403', '找出隐蔽在高维观测数据中有意义的低维向量', '高维数据挖掘概述 (1)', 'p402', 'TECHNIQUE'),

-- 技术原理
('c404', 'e405', 'r404', '非线性降维技术通常基于线性降维技术', '高维数据挖掘概述 (2)', 'p402', 'PRINCIPLE'),
('c405', 'e409', 'r406', '将原始输入映射为低维数据', '数据降维 (2)', 'p403', 'MECHANISM'),
('c406', 'e409', 'r407', '将低维数据映射成高维数据', '数据降维 (3)', 'p403', 'MECHANISM'),

-- 算法实现
('c407', 'e412', 'r408', '分类时对每个类别计算P(c_k)P(x_i|c_k)', '数据分类 (1)', 'p404', 'ALGORITHM'),
('c408', 'e413', 'r409', '在样本空间中找出一个超平面来对数据进行分类', '数据分类 (10)', 'p404', 'ALGORITHM'),
('c409', 'e419', 'r415', '随机选择k个数据对象作为初始簇中心点', '数据聚类 (6)', 'p405', 'ALGORITHM'),

-- 算法特性
('c410', 'e412', 'r417', '决策存在错误率', '总结 (1)', 'p406', 'LIMITATION'),
('c411', 'e409', 'r418', '性能对超参数敏感', '总结 (2)', 'p406', 'CHARACTERISTIC');

-- 6. 插入页面定位数据
INSERT INTO page_locations VALUES
-- 核心概念定位
('loc401', 'p401', 'e401', 'r401', 100, 120, 400, 180, 'EXAMPLE'),
('loc402', 'p402', 'e402', 'r402', 80, 150, 420, 200, 'DEFINITION'),
('loc403', 'p402', 'e404', 'r403', 90, 160, 410, 210, 'TECHNIQUE'),

-- 技术原理定位
('loc404', 'p403', 'e409', NULL, 150, 200, 450, 250, 'DIAGRAM'),
('loc405', 'p403', 'e410', 'r406', 120, 180, 420, 220, 'COMPONENT'),
('loc406', 'p403', 'e411', 'r407', 130, 190, 430, 230, 'COMPONENT'),

-- 算法定位
('loc407', 'p404', 'e412', 'r408', 140, 210, 440, 240, 'ALGORITHM'),
('loc408', 'p405', 'e419', 'r415', 160, 230, 460, 260, 'ALGORITHM'),
('loc409', 'p406', 'e412', 'r417', 170, 240, 470, 270, 'CHARACTERISTIC');

-- =============================================
-- 第5章 视觉数据分析 知识图谱数据
-- =============================================

-- 1. 插入PPT文件记录
INSERT INTO ppt_files VALUES (
    'f005',
    '第5章_视觉数据分析.pptx',
    45,
    NOW(),
    '8i9j0k1l2m3n4o5p6q7r'
);

-- 2. 插入PPT页面记录
INSERT INTO ppt_pages VALUES
('p501', 'f005', 1, '概述', '视觉数据分析基础', '["CNN","特征提取"]'),
('p502', 'f005', 2, '目标检测', 'YOLO算法', '["边界框","置信度"]'),
('p503', 'f005', 3, '图像分割', 'Mask R-CNN', '["RoI","FCN"]'),
('p504', 'f005', 4, '视频目标跟踪', 'Siamese FC', '["模板匹配","实时性"]'),
('p505', 'f005', 5, '总结', '算法对比', '["应用场景","优缺点"]');

-- 3. 插入实体数据
INSERT INTO entities VALUES
-- 核心概念
('e501', '边界框', '元素', '目标检测中的矩形定位框', '目标检测 (1)', 'p502'),
('e502', '局部连接', '结构', 'CNN层间的稀疏连接方式', '目标检测 (2)', 'p502'),
('e503', '卷积核', '组件', '特征提取的滑动窗口滤波器', '目标检测 (3)', 'p502'),
('e504', 'YOLO', '算法', '实时目标检测算法', '目标检测 (5)', 'p502'),
('e505', 'NMS', '方法', '非极大值抑制算法', 'YOLO算法训练 (4)', 'p502'),

-- 图像分割
('e506', '区域一致性', '原则', '图像分割的质量标准', '图像分割 (1)', 'p503'),
('e507', 'RoI对齐', '操作', '特征图标准化处理', 'Mask R-CNN(3)', 'p503'),
('e508', 'ResNet101', '模型', '深度卷积神经网络', 'Mask R-CNN算法示例 (2)', 'p503'),

-- 视频跟踪
('e509', '初始位置', '输入', '跟踪算法的起始帧信息', '视频目标跟踪 (1)', 'p504'),
('e510', '监控系统', '应用', '视频分析的实际场景', '视频目标跟踪 (1)', 'p504'),
('e511', 'Mask R-CNN', '算法', '实例分割框架', '总结', 'p505');

-- 4. 插入关系数据
INSERT INTO relations VALUES
-- 目标检测
('r501', 'e501', 'e501', '确定', '边界框确定目标位置'),
('r502', 'e502', 'e502', '减少', '局部连接减少参数数量'),
('r503', 'e503', 'e503', '计算', '卷积核计算区域特征'),
('r504', 'e504', 'e504', '结合', 'YOLO结合特征与定位'),
('r505', 'e505', 'e505', '选择', 'NMS选择最高置信框'),

-- 图像分割
('r506', 'e506', 'e506', '保持', '区域划分保持特征一致性'),
('r507', 'e507', 'e507', '调整', 'RoI对齐调整特征维度'),
('r508', 'e508', 'e508', '提取', 'ResNet101提取深度特征'),

-- 视频跟踪
('r509', 'e509', 'e509', '用于', '初始位置用于持续跟踪'),
('r510', 'e510', 'e510', '执行', '监控系统执行实时跟踪'),

-- 应用实例
('r511', 'e511', 'e511', '应用于', 'Mask R-CNN应用于图像分割');

-- 5. 插入引用数据
INSERT INTO citations VALUES
-- 目标检测
('c501', 'e501', 'r501', '利用矩形边界框来确定图像中目标所在的位置及大小', '目标检测 (1)', 'p502', 'METHOD'),
('c502', 'e504', 'r504', '将特征提取和检测框定位两个步骤相结合', '目标检测 (5)', 'p502', 'PRINCIPLE'),

-- 图像分割
('c503', 'e507', 'r507', '将RoI与原特征图对齐并统一维度大小', 'Mask R-CNN(3)', 'p503', 'TECHNIQUE'),
('c504', 'e508', 'r508', '使用基于CNN实现的ResNet101提取特征', 'Mask R-CNN算法示例 (2)', 'p503', 'IMPLEMENTATION'),

-- 应用场景
('c505', 'e511', 'r511', '基于Mask R-CNN算法对桌面图像分割', '总结', 'p505', 'EXAMPLE');

-- 6. 插入页面定位数据
INSERT INTO page_locations VALUES
-- 目标检测
('loc501', 'p502', 'e501', 'r501', 100, 150, 400, 200, 'DIAGRAM'),
('loc502', 'p502', 'e504', 'r504', 120, 180, 420, 220, 'ALGORITHM'),

-- 图像分割
('loc503', 'p503', 'e507', NULL, 140, 200, 440, 240, 'FLOWCHART'),
('loc504', 'p503', 'e508', 'r508', 160, 220, 460, 260, 'ARCHITECTURE'),

-- 应用实例
('loc505', 'p505', 'e511', 'r511', 180, 240, 480, 280, 'DEMO');

-- 6. 插入第6章PPT文件记录
INSERT INTO ppt_files VALUES (
    'f006',
    '第6章_文本数据分析.pptx',
    20,
    NOW(),
    'a1b2c3d4e5f6g7h8i9j0'
);

-- 7. 插入第6章PPT页面记录
INSERT INTO ppt_pages VALUES
('p601', 'f006', 1, '引例', '问答系统场景', '["问答系统","知识库","语义信息"]'),
('p602', 'f006', 2, '文本数据分析概述', '文本数据定义', '["文本数据","特征提取","统计分析"]'),
('p603', 'f006', 3, '语言模型', '传统语言模型', '["Word2Vec","CBOW","Skip-gram"]'),
('p604', 'f006', 4, '语言模型', 'BERT模型', '["Transformer","编码器","解码器","位置嵌入"]'),
('p605', 'f006', 5, '情感分析', '情感分析方法', '["篇章级","句子级","属性级","情感词典"]'),
('p606', 'f006', 6, '机器翻译', '机器翻译模型', '["LSTM","编码器-解码器","注意力机制"]');

-- 8. 插入第6章实体数据
INSERT INTO entities VALUES
-- 文本分析基础
('e601', '文本数据', '概念', '以文本形式表示的数据，包含文字、字符和符号等信息', '文本数据分析概述', 'p602'),
('e602', '特征提取', '方法', '从文本中提取有意义的特征表示', '文本数据分析概述', 'p602'),
('e603', '统计分析', '方法', '对文本特征进行统计分析以挖掘知识', '文本数据分析概述', 'p602'),

-- 语言模型
('e604', 'Word2Vec', '模型', '生成词向量的语言模型', '语言模型(3)', 'p603'),
('e605', 'CBOW', '方法', '通过上下文预测当前词', '语言模型(3)', 'p603'),
('e606', 'Skip-gram', '方法', '通过当前词预测上下文', '语言模型(3)', 'p603'),
('e607', 'BERT', '模型', '基于Transformer的双向预训练模型', '语言模型(4)', 'p604'),
('e608', '位置嵌入', '技术', '编码文本位置信息的表示方法', '语言模型(4)', 'p604'),

-- 情感分析
('e609', '篇章级分析', '方法', '对整个文本的情感倾向分析', '情感分析(1)', 'p605'),
('e610', '情感词典', '资源', '包含情感词及其倾向的词典', '情感分析(2)', 'p605'),

-- 机器翻译
('e611', 'LSTM', '模型', '长短期记忆网络模型', '机器翻译(2)', 'p606'),
('e612', '注意力机制', '技术', '动态关注不同位置信息的机制', '机器翻译(4)', 'p606');

-- 9. 插入第6章关系数据
INSERT INTO relations VALUES
-- 文本分析
('r601', 'e601', 'e602', '通过', '文本数据通过特征提取转换为可分析形式'),
('r602', 'e602', 'e603', '结合', '特征提取结合统计分析挖掘知识'),

-- 语言模型
('r603', 'e604', 'e605', '包含', 'Word2Vec包含CBOW方法'),
('r604', 'e604', 'e606', '包含', 'Word2Vec包含Skip-gram方法'),
('r605', 'e607', 'e608', '使用', 'BERT使用位置嵌入编码位置信息'),

-- 情感分析
('r606', 'e609', 'e610', '基于', '篇章级分析可基于情感词典实现'),

-- 机器翻译
('r607', 'e611', 'e612', '结合', 'LSTM结合注意力机制提升翻译效果');

-- 10. 插入第6章引用数据
INSERT INTO citations VALUES
-- 文本分析
('c601', 'e601', 'r601', '以文本形式表示的数据，包含自然语言中的文字、字符和符号等信息', '文本数据分析概述', 'p602', 'DEFINITION'),
('c602', 'e604', 'r603', 'Word2Vec是用于生成词向量的语言模型，通过预测单词的上下文将单词表示为连续空间中的向量', '语言模型(3)', 'p603', 'MODEL'),

-- 语言模型
('c603', 'e607', 'r605', 'BERT网络结构：双向Transformer预训练模型+多层Transformer编码器→文本表示和建模', '语言模型(4)', 'p604', 'ARCHITECTURE'),

-- 情感分析
('c604', 'e609', NULL, '通过对文本进行建模分析，确定其中包含的正面、负面或中性等情感倾向', '情感分析(1)', 'p605', 'METHOD'),

-- 机器翻译
('c605', 'e612', 'r607', '通过注意力机制充分学习所有隐藏状态以动态表示不同时刻的上下文向量', '机器翻译(4)', 'p606', 'TECHNIQUE');

-- 11. 插入第6章页面定位数据
INSERT INTO page_locations VALUES
-- 文本分析
('loc601', 'p602', 'e601', NULL, 100, 120, 300, 180, 'DEFINITION'),
('loc602', 'p602', 'e602', 'r601', 120, 200, 320, 260, 'PROCESS'),

-- 语言模型
('loc603', 'p604', 'e607', 'r605', 150, 220, 350, 280, 'ARCHITECTURE'),
('loc604', 'p604', 'e608', NULL, 180, 240, 380, 300, 'TECHNIQUE'),

-- 机器翻译
('loc605', 'p606', 'e612', 'r607', 200, 260, 400, 320, 'MECHANISM');

-- 12. 插入第7章PPT文件记录
INSERT INTO ppt_files VALUES (
    'f007',
    '第7章_图分析算法.pptx',
    25,
    NOW(),
    'k1l2m3n4o5p6q7r8s9t0'
);

-- 13. 插入第7章PPT页面记录
INSERT INTO ppt_pages VALUES
('p701', 'f007', 1, '引例', '论文分类问题', '["节点分类","有监督学习"]'),
('p702', 'f007', 2, '引例', '论文检索问题', '["链接预测","引用关系"]'),
('p703', 'f007', 3, '引例', '社区发现问题', '["无监督聚类","学术团体"]'),
('p704', 'f007', 4, '图数据分析概述', '图分析任务', '["节点级","边级","图级"]'),
('p705', 'f007', 5, '图神经网络', 'GNN基础', '["GCN","GAT","MPNN"]'),
('p706', 'f007', 6, '节点分类', '传统与深度方法', '["Relational Classification","GCN分类"]'),
('p707', 'f007', 7, '链接预测', 'GCN链接预测', '["编码器-解码器","邻接矩阵重构"]'),
('p708', 'f007', 8, '社区发现', 'GCN社区检测', '["模块度优化","谱聚类"]'),
('p709', 'f007', 9, '评价指标', '社区发现指标', '["AUC","NMI","模块度"]');

-- 14. 插入第7章实体数据
INSERT INTO entities VALUES
-- 核心概念
('e701', '图数据', '概念', '由节点和边组成的非结构化数据', '图数据分析概述 (1)', 'p704'),
('e702', '节点分类', '任务', '对图中未标注节点进行预测的任务', '节点分类 (1)', 'p706'),
('e703', '链接预测', '任务', '预测节点间潜在关系的任务', '链接预测 (1)', 'p707'),
('e704', '社区发现', '任务', '挖掘图中紧密连接子结构的任务', '社区发现 (1)', 'p708'),

-- 算法模型
('e705', 'GCN', '模型', '图卷积神经网络', '图神经网络 (1)', 'p705'),
('e706', 'GAT', '模型', '图注意力网络', '图数据分析概述 (4)', 'p705'),
('e707', '编码器-解码器', '架构', '用于链接预测的模型结构', '链接预测 (3)', 'p707'),

-- 技术方法
('e708', '邻接矩阵重构', '方法', '通过解码器重构节点连接关系', '链接预测 (3)', 'p707'),
('e709', '模块度优化', '方法', '社区发现的质量优化指标', '社区发现 (4)', 'p708'),
('e710', 'AUC', '指标', '评估模型整体预测能力的指标', '评价指标 (3)', 'p709');

-- 15. 插入第7章关系数据
INSERT INTO relations VALUES
-- 概念关联
('r701', 'e701', 'e702', '支持', '图数据结构支持节点分类任务'),
('r702', 'e701', 'e703', '支持', '图数据结构支持链接预测任务'),
('r703', 'e701', 'e704', '支持', '图数据结构支持社区发现任务'),

-- 算法依赖
('r704', 'e705', 'e706', '互补', 'GCN与GAT互为补充的图神经网络模型'),
('r705', 'e705', 'e707', '组成', 'GCN可作为编码器-解码器架构的组件'),

-- 技术流程
('r706', 'e707', 'e708', '生成', '编码器-解码器通过邻接矩阵重构预测链接'),
('r707', 'e704', 'e709', '优化', '社区发现通过模块度优化提升质量'),
('r708', 'e703', 'e710', '评估', '链接预测结果可通过AUC指标评估');

-- 16. 插入第7章引用数据
INSERT INTO citations VALUES
-- 核心概念
('c701', 'e701', 'r701', '挖掘图数据中的知识，为基于图数据的分析应用提供支撑', '图数据分析概述 (1)', 'p704', 'PRINCIPLE'),
('c702', 'e705', 'r704', '图卷积神经网络（GCN）对边特征、节点特征、图特征进行聚合及更新操作', '图数据分析概述 (3)', 'p705', 'MODEL'),

-- 算法实现
('c703', 'e707', 'r705', '用于链接预测的GCN模型主要包括输入层、编码器和解码器', '链接预测 (3)', 'p707', 'ARCHITECTURE'),
('c704', 'e708', NULL, '通过解码器计算节点间的点积和，得到重构邻接矩阵', '链接预测 (3)', 'p707', 'TECHNIQUE'),

-- 评估指标
('c705', 'e710', 'r708', 'AUC不受阈值影响，可直观反映模型的整体预测能力', '评价指标 (3)', 'p709', 'METRIC');

-- 17. 插入第7章页面定位数据
INSERT INTO page_locations VALUES
-- 核心概念
('loc701', 'p704', 'e701', NULL, 120, 150, 320, 200, 'CONCEPT'),
('loc702', 'p705', 'e705', 'r704', 140, 180, 340, 230, 'MODEL_ARCH'),

-- 算法流程
('loc703', 'p707', 'e707', 'r705', 160, 210, 360, 260, 'PROCESS_FLOW'),
('loc704', 'p708', 'e709', 'r707', 180, 240, 380, 290, 'OPTIMIZATION'),

-- 评估指标
('loc705', 'p709', 'e710', NULL, 200, 270, 400, 320, 'METRIC_DIAGRAM');

-- 18. 插入第8章PPT文件记录
INSERT INTO ppt_files VALUES (
    'f008',
    '第8章_知识图谱.pptx',
    30,
    NOW(),
    'u1v2w3x4y5z6a7b8c9d0'
);

-- 19. 插入第8章PPT页面记录
INSERT INTO ppt_pages VALUES
('p801', 'f008', 1, '引例', '知识表示挑战', '["知识存储","多源异构"]'),
('p802', 'f008', 2, '知识图谱概述', 'KG定义与应用', '["图模型","智能问答"]'),
('p803', 'f008', 3, '知识图谱构建', '三元组获取', '["NER","关系抽取","联合抽取"]'),
('p804', 'f008', 4, '知识图谱构建', 'BERT-BiLSTM-CRF模型', '["序列标注","BIOES"]'),
('p805', 'f008', 5, '知识图谱嵌入', '嵌入模型分类', '["TransE","RESCAL"]'),
('p806', 'f008', 6, '知识图谱推理', '推理方法分类', '["演绎推理","AMIE算法"]'),
('p807', 'f008', 7, '知识图谱推理', '神经网络推理', '["NTN","R-GCN"]');

-- 20. 插入第8章实体数据
INSERT INTO entities VALUES
-- 核心概念
('e801', '知识图谱', '概念', '用图模型描述知识和建模万物关联的技术', '知识图谱概述 (1)', 'p802'),
('e802', '三元组', '结构', '<头实体,关系,尾实体>的基础知识表示单元', '知识图谱构建 (1)', 'p803'),
('e803', '命名实体识别', '任务', '从文本中识别特定类型实体的任务', '知识图谱构建 (2)', 'p803'),
('e804', '关系抽取', '任务', '识别实体间语义关系的任务', '知识图谱构建 (7)', 'p803'),

-- 模型方法
('e805', 'BERT-BiLSTM-CRF', '模型', 'NER任务的端到端深度学习模型', '知识图谱构建 (3)', 'p804'),
('e806', 'TransE', '模型', '将关系视为头尾实体向量平移的距离模型', '知识图谱嵌入 (2)', 'p805'),
('e807', 'AMIE算法', '算法', '基于规则学习的知识推理算法', '知识图谱推理 (4)', 'p806'),
('e808', 'R-GCN', '模型', '考虑关系类型的图神经网络推理模型', '知识图谱推理 (10)', 'p807'),

-- 技术组件
('e809', 'BIOES标注', '方法', '序列标注任务的标签规范体系', '知识图谱构建 (4)', 'p804'),
('e810', '注意力层', '组件', '生成权重向量聚焦关键信息的网络层', '知识图谱构建 (8)', 'p804');

-- 21. 插入第8章关系数据
INSERT INTO relations VALUES
-- 概念关联
('r801', 'e801', 'e802', '由...组成', '知识图谱由三元组构成基本知识单元'),
('r802', 'e801', 'e803', '依赖', '知识图谱构建依赖命名实体识别'),
('r803', 'e801', 'e804', '依赖', '知识图谱构建依赖关系抽取'),

-- 模型架构
('r804', 'e805', 'e809', '采用', 'BERT-BiLSTM-CRF采用BIOES标注体系'),
('r805', 'e806', 'e806', '改进', 'TransH通过投影解决TransE的局限性'),
('r806', 'e808', 'e808', '扩展', 'R-GCN在GCN基础上增加关系特定编码'),

-- 技术流程
('r807', 'e803', 'e804', '衔接', 'NER完成后需进行关系抽取'),
('r808', 'e807', 'e807', '包含', 'AMIE算法包含三个规则挖掘算子'),
('r809', 'e810', 'e804', '优化', '注意力层优化关系抽取的句子表示');

-- 22. 插入第8章引用数据
INSERT INTO citations VALUES
-- 核心概念
('c801', 'e801', 'r801', '知识图谱（Knowledge Graph, KG）是一种用图模型描述知识和建模世界万物之间关联关系的技术方法', '知识图谱概述 (1)', 'p802', 'DEFINITION'),
('c802', 'e802', NULL, '在古典名著《西游记》中，"菩提老祖和唐三藏是孙悟空的师傅"可由两个三元组表示', '知识图谱概述 (2)', 'p802', 'EXAMPLE'),

-- 构建方法
('c803', 'e805', 'r804', '以BERT作为基础输入层编码方式，充分挖掘出字符的深层特征', '知识图谱构建 (3)', 'p804', 'ARCHITECTURE'),
('c804', 'e809', NULL, 'BIO方式："B-X"代表"X"类型实体的开头，"I-X"代表中间或结尾，"O"代表不属于任何类型实体', '知识图谱构建 (4)', 'p804', 'STANDARD'),

-- 推理技术
('c805', 'e807', 'r808', 'AMIE算法维护一个规则队列，通过三个挖掘算子扩展规则', '知识图谱推理 (7)', 'p806', 'ALGORITHM'),
('c806', 'e808', 'r806', 'R-GCN首先对每个实体进行编码，每层实体特征由上一层自身和邻居特征加权求和得到', '知识图谱推理 (10)', 'p807', 'MODEL');

-- 23. 插入第8章页面定位数据
INSERT INTO page_locations VALUES
-- 核心概念
('loc801', 'p802', 'e801', 'r801', 100, 120, 300, 180, 'DEFINITION'),
('loc802', 'p803', 'e802', NULL, 120, 150, 320, 200, 'STRUCTURE'),

-- 模型架构
('loc803', 'p804', 'e805', 'r804', 140, 180, 340, 230, 'MODEL_DIAGRAM'),
('loc804', 'p805', 'e806', 'r805', 160, 210, 360, 260, 'MODEL_COMPARE'),

-- 推理算法
('loc805', 'p807', 'e808', 'r806', 180, 240, 380, 290, 'INFERENCE_FLOW');

-- 24. 插入第9章PPT文件记录
INSERT INTO ppt_files VALUES (
    'f009',
    '第9章_贝叶斯网.pptx',
    28,
    NOW(),
    'e1f2g3h4i5j6k7l8m9n0'
);

-- 25. 插入第9章PPT页面记录
INSERT INTO ppt_pages VALUES
('p901', 'f009', 1, '引例', '医疗诊断案例', '["不确定性","条件概率"]'),
('p902', 'f009', 2, '贝叶斯网概念', 'BN基础组件', '["DAG","CPT"]'),
('p903', 'f009', 3, '贝叶斯网参数学习', '最大似然估计', '["MLE","参数学习"]'),
('p904', 'f009', 4, '贝叶斯网结构学习', 'BIC评分算法', '["爬山法","模型选择"]'),
('p905', 'f009', 5, '概率推理', '精确推理算法', '["VE算法","联合概率分解"]'),
('p906', 'f009', 6, '概率推理', '近似推理算法', '["Gibbs采样","MCMC"]');

-- 26. 插入第9章实体数据
INSERT INTO entities VALUES
-- 核心概念
('e901', '贝叶斯网', '模型', '用有向无环图和条件概率表表示概率关系的模型', '贝叶斯网概念 (1)', 'p902'),
('e902', 'DAG', '结构', '有向无环图，描述变量间的因果关系', '贝叶斯网概念 (1)', 'p902'),
('e903', 'CPT', '组件', '条件概率表，存储节点变量的概率分布', '贝叶斯网概念 (1)', 'p902'),

-- 学习方法
('e904', '最大似然估计', '方法', '基于样本数据计算条件概率参数的统计方法', '参数学习 (2)', 'p903'),
('e905', 'BIC评分', '指标', '平衡模型拟合度和复杂度的结构选择标准', '结构学习 (2)', 'p904'),

-- 推理算法
('e906', 'VE算法', '算法', '通过变量消元实现精确概率推理的方法', '概率推理 (5)', 'p905'),
('e907', 'Gibbs采样', '算法', '基于马尔科夫链的近似推理算法', '概率推理 (10)', 'p906');

-- 27. 插入第9章关系数据
INSERT INTO relations VALUES
-- 模型组成
('r901', 'e901', 'e902', '包含', '贝叶斯网必须包含DAG结构'),
('r902', 'e901', 'e903', '包含', '贝叶斯网必须包含CPT参数表'),

-- 学习过程
('r903', 'e904', 'e904', '应用于', '最大似然估计用于参数学习'),
('r904', 'e905', 'e905', '优化', 'BIC评分通过惩罚项防止过拟合'),

-- 推理技术
('r905', 'e906', 'e906', '实现', 'VE算法通过分解联合分布简化计算'),
('r906', 'e907', 'e907', '通过', 'Gibbs采样通过降低精度要求提高效率');

-- 28. 插入第9章引用数据
INSERT INTO citations VALUES
-- 核心概念
('c901', 'e901', 'r901', '贝叶斯网（Bayesian Network, BN）由有向无环图和条件概率表组成', '贝叶斯网概念 (1)', 'p902', 'DEFINITION'),
('c902', 'e902', NULL, 'S："吸烟" A："发烧" B："呼吸困难" L："肺癌" C："感染COVID-19"', '贝叶斯网概念 (2)', 'p902', 'EXAMPLE'),

-- 学习方法
('c903', 'e904', 'r903', '基于样本数据计算变量节点的条件概率参数', '参数学习 (1)', 'p903', 'METHOD'),
('c904', 'e905', 'r904', 'BIC评分：在大样本前提下对边缘似然函数的一种近似', '结构学习 (2)', 'p904', 'FORMULA'),

-- 推理算法
('c905', 'e906', 'r905', '利用变量间的条件独立性，分解联合概率分布', '概率推理 (4)', 'p905', 'ALGORITHM'),
('c906', 'e907', 'r906', '通过降低对精度的要求，在限定时间内得到近似解', '概率推理 (1)', 'p906', 'PRINCIPLE');

-- 29. 插入第9章页面定位数据
INSERT INTO page_locations VALUES
-- 核心概念
('loc901', 'p902', 'e901', 'r901', 100, 120, 300, 180, 'MODEL_STRUCT'),
('loc902', 'p902', 'e902', 'r901', 120, 150, 320, 200, 'GRAPH_DIAGRAM'),

-- 学习算法
('loc903', 'p903', 'e904', NULL, 140, 180, 340, 230, 'PARAM_LEARNING'),
('loc904', 'p904', 'e905', 'r904', 160, 210, 360, 260, 'STRUCT_OPTIM'),

-- 推理算法
('loc905', 'p906', 'e907', 'r906', 180, 240, 380, 290, 'SAMPLING_DEMO');